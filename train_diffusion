# training 
import numpy as np
import os
import tqdm
from sklearn.model_selection import train_test_split


import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F


import src.utils as utils
import src.models as models

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')


# Load data X
data_dir = 'Data'
file_name = 'input.pkl'
file_name_label = 'output.pkl'
file_path = os.path.join(data_dir, file_name)
file_path_label = os.path.join(data_dir, file_name_label)

data = utils.read_pkl(file_path)
label = utils.read_pkl(file_path_label)

label_encoded, label_map = utils.label_encoder(label)

X_train, X_test, y_train, y_test = train_test_split(
    data,
    label_encoded,
    test_size = 0.2,
    random_state = 69,
    shuffle = True,
)

(X_train_scaled, X_test_scaled),scaler_list = utils.scale_it(X_train, X_test)

# X_train_scaled_tensor_x, y_train_tensor_x = utils.tensor_it(X_train_scaled,y_train)
# X_test_scaled_tensor_x, y_test_tensor_x = utils.tensor_it(X_test_scaled,y_test)
X_train_scaled_tensor_x, _ = utils.tensor_it(X_train_scaled,y_train)
X_test_scaled_tensor_x, _ = utils.tensor_it(X_test_scaled,y_test)

# Load Data Z
X_train_scaled_tensor = utils.read_pkl('Data/aux_features/features_train.pkl')
X_test_scaled_tensor = utils.read_pkl('Data/aux_features/features_test.pkl')
# y_train_tensor = utils.read_pkl('Data/aux_features/labels_train.pkl')
# y_test_tensor = utils.read_pkl('Data/aux_features/labels_test.pkl')

# Data Loader
train_loader = utils.make_loader(
    X_train_scaled_tensor,
    X_train_scaled_tensor_x[:,2,:,:],
    # y_train_tensor,
    128
)
test_loader = utils.make_loader(
    X_test_scaled_tensor,
    X_test_scaled_tensor_x[:,2,:,:],
    # y_test_tensor,
    128
)

model = models.UNET(1,2,1)


# Training UNET (diffuxion model)
# ==================================================
MODE = 'diffusion'
MODEL = model
EPOCHS = 10
TRAIN_DATALOADER = train_loader
TEST_DATALOADER = test_loader
OPTIMIZER = optim.Adam(model.parameters(), lr=0.00001)
CRITERION = nn.MSELoss()
EARLY_STOPPING = 'test_loss'
SHOW_GRAD = False
T = 10


def fix_temp():
    temp_dir = 'temp'
    if not os.path.exists(temp_dir):
        os.makedirs(temp_dir)
    else:
        for filename in os.listdir(temp_dir):
            file_path = os.path.join(temp_dir, filename)
            if os.path.isfile(file_path):
                os.remove(file_path)

def save_weight_dic():
        for k,v in zip(MODEL.weight_dic.keys(), MODEL.weight_dic.values()):
            weight_name = f'{MODE}_{k}_{np.abs(MODEL.metrics_best[k]):.6f}.pth'
            weight_path = os.path.join('temp', weight_name)
            torch.save(v, weight_path)
            print(f'Weight <{weight_path}> saved successfully')

fix_temp()
dfp = models.DiffusionProcess(T, 0.0002, 0.05)

train_losses, train_gen_loss, test_losses, test_gen_loss = [], [], [], []

for epoch in range(EPOCHS):

    MODEL.train()
    train_loss = 0.0
    train_gen_loss = 0.0

    progress_bar = tqdm.tqdm(enumerate(TRAIN_DATALOADER), total=len(TRAIN_DATALOADER), desc=f'Epoch {epoch + 1}/{EPOCHS}')

    for i,(batch_z, batch_x) in progress_bar:
         
        batch_z = batch_z.to(device)
        batch_x = batch_x.to(device)

        t = torch.randint(0, T, (batch_z.shape[0],), device=device)
        t_embd = models.sinusoidal_embedding(t, 128)

        batch_z_noisy, batch_noise = dfp.q_sample(batch_z,t)

        OPTIMIZER.zero_grad()

        noise_hat = MODEL(batch_x, batch_z_noisy, t_embd)

        loss = CRITERION(noise_hat, batch_noise)

        loss.backward()
        OPTIMIZER.step()






